# -*- coding: utf-8 -*-
"""Body_Fat_Prediction_Project.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/12ZSPYgDq2LrTorIJxN5qW3YtY5GzjU0N

# **Body Fat Prediction Project**
"""

# This Python 3 environment comes with many helpful analytics libraries installed
# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python
# For example, here's several helpful packages to load

import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)


# Import required libraries
import tensorflow as tf
import pandas as pd
import matplotlib.pyplot as plt

"""
The following code shows reading a CSV file, "bodyfat.csv," using pandas and storing it in the variable df. This allows us to access and analyze the dataset."""

FILE_DIR="bodyfat.csv"

# Read in the insurance dataset
df = pd.read_csv(FILE_DIR)

# Check out the insurance dataset
df.head()

df.shape

df.info()

"""Set the target"""

target="BodyFat"

"""**Make_Column_Transformer**

The next code block extracts the numerical features from the dataset and stores them in the numerical_features list. The target variable is excluded from the list. This code is done to separate the numerical features for further processing.
"""

numerical_features = df._get_numeric_data().columns.to_list()
numerical_features.remove(target)
numerical_features

"""In the subsequent code, the categorical features are extracted from the dataset and stored in the categorical_features list. This is done to separate the categorical features for preprocessing."""

categorical_features = df.select_dtypes(include=['object']).columns.to_list()
categorical_features

"""The next code block imports necessary libraries and initializes a column transformer, ct, which will be used for data normalization and preprocessing.

After that, the code creates input features X and target variable y by splitting the dataset. The training and test sets (X_train, X_test, y_train, y_test) are generated using the train_test_split function.

The following code fits the column transformer ct on the training data and transforms both the training and test data using the fitted transformer. This is important to normalize and preprocess the data consistently across the training and test sets.
"""

from sklearn.compose import make_column_transformer
from sklearn.preprocessing import MinMaxScaler, OneHotEncoder
from sklearn.model_selection import train_test_split

# Create column transformer (this will help us normalize/preprocess our data)
ct = make_column_transformer(
    (MinMaxScaler(), numerical_features))

# Create X & y
X = df.drop(target, axis=1)
y = df[target]

# Build our train and test sets (use random state to ensure same split as before)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Fit column transformer on the training data only (doing so on test data would result in data leakage)
ct.fit(X_train)

# Transform training and test data with normalization (MinMaxScalar) and one hot encoding (OneHotEncoder)
X_train_normal = ct.transform(X_train)
X_test_normal = ct.transform(X_test)

# Non-normalized and non-one-hot encoded data example
X_train.loc[0]

# Normalized and one-hot encoded example
X_train_normal[0]

# Notice the normalized/one-hot encoded shape is larger because of the extra columns
X_train_normal.shape, X_train.shape

"""Next, the code block sets up a model checkpoint, cc, which will save the best model during training based on the validation loss."""

from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint

cc = ModelCheckpoint('best_model.h5',
                             monitor='val_loss',
                             mode='min',
                             save_best_only=True,
                             verbose=1)

"""The code sets a random seed for reproducibility and builds a sequential model, model_dn, with three dense layers. The model is compiled with a mean absolute error (MAE) loss function, Adam optimizer, and MAE metric.

The model is then trained for 1500 epochs using the training data, and the validation data is used to monitor the model's performance. The model checkpoint callback is included to save the best model based on the validation loss.
"""

# Set random seed
tf.random.set_seed(42)

# Build the model (3 layers, 100, 10, 1 units)
model_dn = tf.keras.Sequential([
  tf.keras.layers.Dense(100),
  tf.keras.layers.Dense(10),
  tf.keras.layers.Dense(1)
])

# Compile the model
model_dn.compile(loss=tf.keras.losses.mae,
                          optimizer=tf.keras.optimizers.Adam(),
                          metrics=['mae'])

# Fit the model for 1000 epochs
model_dn.fit(X_train_normal, y_train, epochs=1500, validation_data=(X_test_normal, y_test), verbose=1, callbacks=[cc])

"""After training, the code evaluates the model's performance on the test data, calculating the loss (model_dn_loss) and MAE (model_dn_mae)."""

# Evaulate the model
model_dn_loss, model_dn_mae = model_dn.evaluate(X_test_normal, y_test)

"""The next code block uses the trained model to make predictions on the test data (X_test_normal) and stores the predictions in test_pred."""

test_pred = model_dn.predict(X_test_normal)
test_pred

y_test.shape, test_pred.shape, tf.squeeze(test_pred).shape

"""The following code defines two utility functions: mean_absolute_scaled_error and evaluate_preds. The mean_absolute_scaled_error function calculates the mean absolute scaled error metric. The evaluate_preds function calculates various evaluation metrics, including MAE, MSE, RMSE, MAPE, MASE, and R-squared score."""

# MASE implemented courtesy of sktime - https://github.com/alan-turing-institute/sktime/blob/ee7a06843a44f4aaec7582d847e36073a9ab0566/sktime/performance_metrics/forecasting/_functions.py#L16
def mean_absolute_scaled_error(y_true, y_pred):
  """
  Implement MASE (assuming no seasonality of data).
  """
  mae = tf.reduce_mean(tf.abs(y_true - y_pred))

  # Find MAE of naive forecast (no seasonality)
  mae_naive_no_season = tf.reduce_mean(tf.abs(y_true[1:] - y_true[:-1])) # our seasonality is 1 day (hence the shifting of 1 day)

  return mae / mae_naive_no_season

def evaluate_preds(y_true, y_pred):
    # Make sure float32 (for metric calculations)
    y_true = tf.cast(y_true, dtype=tf.float32)
    y_pred = tf.cast(y_pred, dtype=tf.float32)

    # Calculate various metrics
    mae = tf.keras.metrics.mean_absolute_error(y_true, y_pred)
    mse = tf.keras.metrics.mean_squared_error(y_true, y_pred)
    rmse = tf.sqrt(mse)
    mape = tf.keras.metrics.mean_absolute_percentage_error(y_true, y_pred)
    mase = mean_absolute_scaled_error(y_true, y_pred)

    # Calculate R-squared score
    ss_res = tf.reduce_sum((y_true - y_pred)**2)
    ss_tot = tf.reduce_sum((y_true - tf.reduce_mean(y_true))**2)
    r2 = 1 - (ss_res / ss_tot)

    # Account for different sized metrics
    if mae.ndim > 0:
        mae = tf.reduce_mean(mae)
        mse = tf.reduce_mean(mse)
        rmse = tf.reduce_mean(rmse)
        mape = tf.reduce_mean(mape)
        mase = tf.reduce_mean(mase)
        r2 = tf.reduce_mean(r2)

    return {"mae": mae.numpy(),
            "mse": mse.numpy(),
            "rmse": rmse.numpy(),
            "mape": str(mape.numpy()) + "%",
            "mase": mase.numpy(),
            "r2": r2.numpy()}

y_test.shape, test_pred.shape

"""Make sure y_test and test_pred have the same shape"""

y_test = tf.squeeze(y_test)
test_pred = tf.squeeze(test_pred)

"""The code applies these utility functions to the test data (y_test and test_pred), generating a dictionary of evaluation metrics."""

evaluate_preds(y_test,test_pred)

"""In the subsequent code block, the actual and predicted values are formatted into a DataFrame, dr, for further analysis and comparison."""

actual_ys = y_test
predicted_ys = model_dn.predict(X_test_normal)
predicted_ys = predicted_ys.flatten()

data = {f'feature_{i}': X_test_normal[:, i] for i in range(X_test_normal.shape[1])}
data['Actual Y'] = actual_ys
data['Predicted Y'] = predicted_ys

dr = pd.DataFrame(data)
dr

"""The next code block ensures that the y_test and test_pred arrays are 1D and then creates a DataFrame, dw, containing the actual and predicted values, as well as the difference and percentage difference between them."""

# Ensure 'ytest' and 'test_pred' are 1D
ytest_1D = tf.squeeze(y_test)
test_pred_1D = tf.squeeze(test_pred)

# Now create the DataFrame
dw = pd.DataFrame({'Actual': ytest_1D, 'Predicted': test_pred_1D})

# Calculate the difference
dw['Difference'] = dw['Predicted'] - dw['Actual']

# Calculate the percentage difference
dw['Percentage Difference'] = (dw['Difference'] / dw['Actual']) * 100

dw = dw.round(2)
dw.head(30)

"""Following that, the code plots the last 200 records of the predicted and actual values to visualize their comparison.

"""

# Get last 200 records from your data
y_pred_sub = test_pred[-200:]
y_test_sub = y_test[-200:]

plt.figure(figsize=(10, 5))
plt.plot(range(len(y_pred_sub)), y_pred_sub, label='Predicted')
plt.plot(range(len(y_test_sub)), y_test_sub, label='Actual')
plt.xlabel('Index')
plt.ylabel('Values')
plt.legend()
plt.title("Actual vs Predicted")
plt.show()

"""Finally, two scatter plots are created to check for linearity between the actual and predicted values. The plots help assess how well the model's predictions align with the actual values."""

plt.figure(figsize=(14,5))
plt.scatter(y_test, test_pred, color='r')
plt.title('Check for Linearity:\n Actual vs Predicted values')
plt.xlabel('Actual values')
plt.ylabel('Predicted values')
plt.show()


model_dn.save("model_dn.h5")